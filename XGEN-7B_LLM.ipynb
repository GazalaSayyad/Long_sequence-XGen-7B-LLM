{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "864d3afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using unk_token, but it is not set yet.\n",
      "Using unk_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# name = 'Salesforce/xgen-7b-8k-inst'\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Salesforce/xgen-7b-8k-inst\",\n",
    "                                          trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c027ab18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuda:0'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_map = {\"cuda:0\" if torch.cuda.is_available() else \"cpu\"}\n",
    "device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c27c69f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea32be0b0f0a40f5a0233a122b9cb9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"Salesforce/xgen-7b-8k-inst\",\n",
    "                                             torch_dtype=torch.float16,\n",
    "                                            #load_in_8bit=True,\n",
    "                                             device_map='auto',offload_folder='C:/gazala_codes/XGEN_LLM/g_llm/')\n",
    "                                        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58993e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"_name_or_path\": \"Salesforce/xgen-7b-8k-inst\",\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 4096,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 11008,\n",
       "  \"max_position_embeddings\": 8192,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 32,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"float16\",\n",
       "  \"transformers_version\": \"4.31.0.dev0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 51200\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a41bb583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"_from_model_config\": true,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"transformers_version\": \"4.31.0.dev0\"\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "712fab04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GenerationConfig\n",
    "generation_config = model.generation_config\n",
    "generation_config.max_new_tokens = 128\n",
    "generation_config.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33492372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerationConfig {\n",
       "  \"_from_model_config\": true,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"max_new_tokens\": 128,\n",
       "  \"pad_token_id\": 50256,\n",
       "  \"transformers_version\": \"4.31.0.dev0\"\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57eeaf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = (\n",
    "    \"A chat between a curious human and an artificial intelligence assistant. \"\n",
    "    \"The assistant gives helpful, detailed, and polite answers to the human's questions.\\n\\n\"\n",
    ")\n",
    "prompt = f\"### Human: What is life?Answer in 1 sentence\\n###\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee8c8703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\n",
      "\n",
      "### Human: What is life?Answer in 1 sentence\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "print(system_prompt + prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34d20a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 19s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputs = tokenizer(system_prompt + prompt,return_tensors=\"pt\").to(model.device)\n",
    "#with torch.inference_model():\n",
    "generations =model.generate(**inputs,generation_config=generation_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "172a7c20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   32,  8537,  1022,   257, 11040,  1692,   290,   281, 11666,  4430,\n",
       "          8796,    13,   383,  8796,  3607,  7613,    11,  6496,    11,   290,\n",
       "         23507,  7429,   284,   262,  1692,   338,  2683,    13,   198,   198,\n",
       "         21017,  5524,    25,  1867,   318,  1204,    30, 33706,   287,   352,\n",
       "          6827,   198, 21017, 15286,    25,  5155,   318,   257,  3716,   290,\n",
       "          8925,  1080,   326,   318, 16264,   416,  3349,    11, 20728,    11,\n",
       "           290, 16711,    13,   198, 50256]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88879056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\n",
      "\n",
      "### Human: What is life?Answer in 1 sentence\n",
      "### Assistant: Life is a complex and dynamic system that is characterized by growth, reproduction, and adaptation.\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(generations[0], skip_special_tokens=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e13bbae",
   "metadata": {},
   "source": [
    "# Prompt Helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10adb823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_prompt(prompt:str,system_prompt:str)->str:\n",
    "    return f\" \"\n",
    "{system_prompt}\n",
    "### Human:{prompt}\n",
    "###\n",
    "\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1a1f029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Human: What is life?Answer in 1 sentence\n",
      "### A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_prompt = (\n",
    "    \"A chat between a curious human and an artificial intelligence assistant. \"\n",
    "    \"The assistant gives helpful, detailed, and polite answers to the human's questions.\\n\\n\"\n",
    ")\n",
    "prompt = f\"### Human: What is life?Answer in 1 sentence\\n###\"\n",
    "print(prompt,system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68a1373a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import textwrap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5866e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_response(response:str, wrap_text: bool = True)-> str:\n",
    "    assistant_prompt = \"Assistant:\"\n",
    "    assistant_start = response.find(assistant_prompt)+len(assistant_prompt)\n",
    "    response = response[assistant_start:response.find(\"<|endoftext|>\")].strip()\n",
    "    if not wrap_text:\n",
    "        return response\n",
    "    return textwrap.fill(response,width=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a75934a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Life is a complex and dynamic system that is characterized by growth, reproduction, and adaptation.\n"
     ]
    }
   ],
   "source": [
    "response = tokenizer.decode(generations[0],skip_special_tokens=True)\n",
    "print(clean_response(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
